# üìä An√°lise Completa do Sistema de Replays/Analytics

## 1. Vis√£o Geral do Sistema

O sistema de replays foi projetado com o objetivo de **capturar jogadas humanas** para extrair padr√µes e estrat√©gias que possam ser usadas para **aprimorar a IA do bot**. O fluxo completo √©:

```
Captura (durante jogo) ‚Üí Armazenamento (IndexedDB) ‚Üí An√°lise (TrainingDigest) ‚Üí Insights (queries) ‚Üí Integra√ß√£o IA
```

### 1.1 Arquivos Principais

| Arquivo | Responsabilidade |
|---------|------------------|
| `ReplayCapture.js` | Captura decis√µes durante o duelo (v3 otimizado) |
| `game/replay/integration.js` | Hooks de eventos do Game.js |
| `ReplayDatabase.js` | Persist√™ncia em IndexedDB |
| `ReplayImporter.js` | Valida√ß√£o, dedup e qualidade |
| `ReplayAnalyzer.js` | Gera√ß√£o de training digests |
| `ReplayInsights.js` | Queries agregadas com anti-vi√©s |
| `PatternMatcher.js` | Detec√ß√£o de combos e padr√µes |
| `priorities.js` | Integra√ß√£o com IA (getReplayModifier) |

---

## 2. An√°lise do Pipeline Atual

### 2.1 Captura de Eventos (ReplayCapture.js) ‚úÖ Bem Implementado

**Pontos Fortes:**
- Vers√£o 3 otimizada com snapshots a cada 5 turnos + deltas
- Dicion√°rio de cartas para evitar repeti√ß√£o de nomes
- Timestamps relativos (t0/dt) para an√°lise de tempo de decis√£o
- Captura de `availableActions` (v4) - **cr√≠tico para ML**
- Suporta ambos jogadores (human e bot)

**Tipos de Decis√£o Capturados:**
- `summon` - com summonType (normal/special/fusion/ascension)
- `attack` - com combatResult (dano, destrui√ß√£o)
- `spell`/`trap_activation`
- `effect` - com effectId e activationZone
- `set_spell_trap`
- `position_change`/`position_choice`
- `chain_response`
- `pass`

**Dados de Contexto (gameState):**
```javascript
{
  playerLP, botLP,
  playerHand: [...], // v3: nomes completos
  playerField: [...], botField: [...],
  playerGraveyard: [...], botGraveyard: [...],
  playerFieldSpell, botFieldSpell,
  playerExtraDeckCount, botExtraDeckCount,
  turn, phase, summonCount
}
```

### 2.2 Integra√ß√£o com Game (integration.js) ‚úÖ Bem Implementado

**Eventos Capturados:**
- `after_summon`, `attack_declared`, `combat_resolved`
- `spell_activated`, `trap_activated`, `effect_activated`
- `position_change`, `position_chosen`, `card_set`
- `chain_response`, `phase_skip`, `turn_start`
- `damage_inflicted`, `card_destroyed`
- `game_over`

**Captura de Available Actions (v4):**
- `main_phase_options` - op√ß√µes de summon, set, activate
- `battle_phase_options` - ataques dispon√≠veis
- `chain_window_options` - respostas de chain
- `summon_position_choice` - attack/defense
- `target_selection_options` - alvos dispon√≠veis

### 2.3 An√°lise e Training Digest (ReplayAnalyzer.js) ‚ö†Ô∏è Parcialmente Implementado

**Pontos Fortes:**
- Reconstr√≥i estado via rolling (snapshot + deltas acumulados)
- Calcula outcome (lpDelta, boardDelta, gameResult)
- Detecta padr√µes (summon_then_effect, lethal_push, etc.)
- Extrai m√©tricas (tempo de decis√£o, distribui√ß√£o de summons)
- An√°lise de opening (primeiros 3 turnos)

**Formato do Digest:**
```javascript
{
  replayId, archetype, matchup,
  turn, phase, actor,
  promptType: "summon" | "attack" | "effect" | ...,
  chosenAction: { type, cardId, summonType, ... },
  availableActions: [...], // v4: op√ß√µes dispon√≠veis
  context: { playerLP, botLP, lpDiff, playerHand, ... },
  outcome: { gameResult, lpDelta, boardDelta },
  decisionTime: 1500 // ms
}
```

### 2.4 Insights e Queries (ReplayInsights.js) ‚ö†Ô∏è Subutilizado

**M√©tricas Dispon√≠veis:**
- `getCardPerformance(cardName)` - winRate, avgActivations, impactScore
- `getTopCardsByWinRate()` - ranking com confidence
- `getOpeningPatterns(archetype)` - sequ√™ncias de abertura com winRate
- `getPhasePreferences(archetype)` - distribui√ß√£o de a√ß√µes por fase
- `getActionInsight(action, gameState)` - score para IA
- `getMatchupStats(archetype)` - winRate por matchup

**Guardrails Anti-vi√©s:**
- minSample = 3 (adaptativo para bases pequenas)
- confidence baseada em sample size
- Cache com TTL de 5 minutos

### 2.5 Integra√ß√£o com IA (priorities.js) ‚ö†Ô∏è Parcialmente Implementado

**Atual:**
```javascript
// getReplayModifier(action, gameState) ‚Üí ¬±10% m√°ximo
// Requer: shadow_duel_replay_insights = "true"
// Guardrails: confidence >= 0.6, sampleSize >= 5
```

**Problema:** A fun√ß√£o existe mas n√£o est√° sendo chamada ativamente durante avalia√ß√£o de a√ß√µes.

---

## 3. Problemas Identificados

### 3.1 Cr√≠tico: AvailableActions Inconsistentes

**Problema:** Algumas decis√µes t√™m `availableActions: null` no digest.

**Causa:** O evento `registerAvailableActions` nem sempre √© disparado antes da decis√£o ser tomada. Isso acontece especialmente em:
- Efeitos triggered automaticamente
- Sele√ß√£o de alvos em cascata
- Decis√µes do bot (s√≥ registra no main_phase)

**Impacto:** Sem availableActions, n√£o √© poss√≠vel treinar o modelo a distinguir entre "escolheu X tendo Y dispon√≠vel" vs "escolheu X porque era a √∫nica op√ß√£o".

### 3.2 M√©dio: Outcome Incompleto

**Problema:** Muitos digests t√™m `outcome.lpDelta: null` e `outcome.boardDelta: null`.

**Causa:** O c√°lculo de outcome depende de encontrar um snapshot futuro do mesmo jogador, que nem sempre existe (ex: se o jogo terminar logo ap√≥s).

**Impacto:** Dificulta avaliar se a decis√£o foi "boa" ou "ruim" em termos de resultado imediato.

### 3.3 M√©dio: Integra√ß√£o com IA Desativada por Default

**Problema:** `shadow_duel_replay_insights` precisa ser ativado manualmente e a fun√ß√£o `getReplayModifier` n√£o √© chamada nas estrat√©gias principais.

**Impacto:** Os dados coletados n√£o est√£o influenciando as decis√µes da IA.

### 3.4 Baixo: Falta de Captura de Decis√µes de Targeting

**Problema:** Quando o humano seleciona alvos (ex: qual monstro destruir), a decis√£o de targeting n√£o √© capturada como evento separado.

**Impacto:** Perdemos informa√ß√£o sobre "por que escolheu esse alvo espec√≠fico".

### 3.5 Baixo: Sem Replay Visual

**Problema:** N√£o h√° forma de reproduzir visualmente um replay salvo.

**Impacto:** Dif√≠cil fazer an√°lise manual qualitativa das partidas.

---

## 4. Recomenda√ß√µes de Melhoria

### 4.1 Curto Prazo (Quick Wins) ‚úÖ IMPLEMENTADO

#### 4.1.1 Garantir AvailableActions em Todas as Decis√µes ‚úÖ
- Adicionada emiss√£o de `target_selection_options` em `session.js`
- Evento emitido quando uma sess√£o de sele√ß√£o √© iniciada para o jogador humano

#### 4.1.2 Melhorar C√°lculo de Outcome ‚úÖ
Implementado em `ReplayAnalyzer.js`:
- Usa delta imediato da decis√£o como fallback quando snapshot futuro n√£o est√° dispon√≠vel
- Acumula deltas entre decis√µes para calcular impacto
- Adiciona campo `source` para indicar origem do c√°lculo

#### 4.1.3 Adicionar M√©tricas de Qualidade de Digest ‚úÖ
Implementado `calculateDigestQualityMetrics()` em `ReplayAnalyzer.js`:
- Calcula score de qualidade (0-100)
- Verifica cobertura de availableActions
- Verifica cobertura de outcome
- Gera recomenda√ß√µes de melhoria

### 4.2 M√©dio Prazo (Robustez) ‚úÖ IMPLEMENTADO

#### 4.2.1 Capturar Decis√µes de Targeting ‚úÖ
Implementado completo:
- Evento `target_selection_options` emitido em `session.js` quando sele√ß√£o inicia
- Evento `target_selected` emitido em `session.js` quando sele√ß√£o √© finalizada
- Listener em `integration.js` para capturar ambos eventos
- M√©todo `captureTargetSelection()` em `ReplayCapture.js`
- Tipo `target_selection` adicionado ao `ReplayAnalyzer.js`

#### 4.2.2 Adicionar M√©tricas de Qualidade de Decis√£o ‚úÖ
Implementado via `calculateDigestQualityMetrics()`:
```javascript
// Exemplo de uso:
const metrics = replayAnalyzer.calculateDigestQualityMetrics(digests);
console.log(metrics.qualityScore); // 0-100
console.log(metrics.recommendations); // [{priority, issue, suggestion}]
```

### 4.3 Pendente (Longo Prazo)
// Para cada digest, calcular "decision quality score"
const qualityScore = calculateDecisionQuality(digest);
// Baseado em: 
// - Outcome positivo?
// - Era a a√ß√£o com maior winRate hist√≥rico?
// - Seguiu padr√£o de opening vencedor?
```

#### 4.2.3 Implementar Replay Viewer B√°sico
Criar componente que l√™ o JSON e reproduz turno a turno visualmente.
*(Pendente)*

### 4.3 Pendente (Longo Prazo - ML Pipeline)

#### 4.3.1 Exportar para Formato ML-Ready
```javascript
// Formato para fine-tuning de modelos
{
  "prompt": "Turn 3, Main1. LP: 6700 vs 8000. Hand: [Aegisbearer, Holy Shield]. Field: [Valiant]. Opp: [Dragon 3000 ATK]. Options: [summon Aegis DEF, activate Holy Shield, pass]. What do you play?",
  "completion": "summon Aegis DEF - Setup defensive wall before opponent can attack.",
  "metadata": { turn, phase, outcome, winRate }
}
```

#### 4.3.2 Sistema de Anota√ß√£o Manual
Dashboard para humano revisar e anotar decis√µes:
- "Esta foi a decis√£o correta?"
- "Por que foi a melhor op√ß√£o?"
- Tags: "lethal setup", "defensive", "resource management"

#### 4.3.3 Feedback Loop Automatizado
```
Replay ‚Üí Digest ‚Üí Train ‚Üí Deploy Bot ‚Üí Capturar Replays ‚Üí Comparar ‚Üí Ajustar
```

---

## 5. M√©tricas Atuais (An√°lise dos Replays)

### 5.1 Volume de Dados
- **Replays salvos:** ~19 arquivos no diret√≥rio `/replays`
- **Training digests gerados:** 1077 samples no √∫ltimo export
- **Qualidade:** Maioria "clean" ou "partial"

### 5.2 Distribui√ß√£o de Decis√µes (do digest analisado)
- `summon`: ~25%
- `attack`: ~20%
- `pass`: ~20%
- `effect`: ~15%
- `spell`: ~10%
- `target_selection`: ~5% *(novo v4)*
- Outros: ~5%

### 5.3 Cobertura de AvailableActions
- Com availableActions: ~60% ‚Üí **Melhorando com v4**
- Sem availableActions (null): ~40% ‚Üí Deve diminuir com novos replays

---

## 6. Roadmap - Status Atual

### Sprint 1 (Imediato) ‚úÖ CONCLU√çDO
- [x] Fix: Garantir availableActions em todas as decis√µes
- [x] Fix: Melhorar c√°lculo de outcome com fallback
- [x] Add: M√©tricas de qualidade para digests

### Sprint 2 (Conclu√≠do nesta PR) ‚úÖ
- [x] Add: Captura de target_selection (eventos + handlers)
- [x] Add: Decision quality score (calculateDigestQualityMetrics)
- [ ] Add: Replay viewer b√°sico (read-only) - *Pendente*

### Sprint 3 (Pendente - 1-2 meses)
- [ ] Add: Export para formato ML-ready
- [ ] Add: Sistema de anota√ß√£o manual
- [ ] Add: Dashboard de compara√ß√£o humano vs bot

---

## 7. Conclus√£o

O sistema de replays est√° **bem arquitetado** e tem todos os componentes necess√°rios para um pipeline completo de captura ‚Üí an√°lise ‚Üí aprendizado.

### Melhorias Implementadas nesta An√°lise:

1. **Outcome Calculation Melhorado** (`ReplayAnalyzer.js`)
   - Usa delta imediato como fallback quando snapshot n√£o est√° dispon√≠vel
   - Adiciona fonte do c√°lculo para rastreabilidade

2. **Captura de Target Selection** (Novo)
   - Evento `target_selection_options` emitido quando sele√ß√£o inicia
   - Evento `target_selected` emitido quando sele√ß√£o √© finalizada
   - Handler completo em `ReplayCapture.js`
   - Integra√ß√£o com digest generation

3. **M√©tricas de Qualidade** (Novo)
   - `calculateDigestQualityMetrics()` para avaliar qualidade dos dados
   - Score 0-100 baseado em completude
   - Recomenda√ß√µes autom√°ticas de melhoria

### Pr√≥ximos Passos Recomendados:

1. **Jogar mais partidas** com o modo replay ativado para coletar dados com as melhorias v4
2. **Ativar `shadow_duel_replay_insights`** para que a IA use os dados coletados
3. **Implementar replay viewer** para an√°lise qualitativa das partidas

Com as melhorias implementadas, o sistema agora captura mais informa√ß√µes sobre decis√µes de targeting e calcula outcomes de forma mais robusta, tornando os dados mais √∫teis para treinar a IA.
